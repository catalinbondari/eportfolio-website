<!DOCTYPE html>
<html lang="en">

<head>

    <!-- Basic Page Needs
    ================================================== -->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Blog - Unlock the Secrets to Choosing the Perfect Machine Learning Algorithm!
    </title>

    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="keywords" content="">

    <!-- Mobile Specific Metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="apple-mobile-web-app-capable" content="yes" />

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700" rel="stylesheet">

    <!-- Favicon
    ================================================== -->
    <link rel="apple-touch-icon" sizes="180x180" href="assets/img/signature-2.png">
    <link rel="icon" type="image/png" sizes="100x100" href="assets/img/signature-2.png">

    <!-- Stylesheets
    ================================================== -->
    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/css/ionicons/css/ionicons.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/style.css" rel="stylesheet">
    <link href="assets/css/responsive.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <header id="masthead" class="site-header" data-anchor-target=".hero"
        data-top="background: rgba(255,255,255,100); padding: 30px 0; box-shadow: 0px 0px 20px 6px rgba(0, 0, 0, 0);"
        data-top-bottom="background: rgba(255,255,255,1); padding: 10px 0; box-shadow: 0px 0px 20px 6px rgba(0, 0, 0, 0.2);">
        <nav id="primary-navigation" class="site-navigation">
            <div class="container">
                <div class="navbar-header page-scroll">

                    <button type="button" class="navbar-toggle collapsed" data-target="#portfolio-perfect-collapse"
                        aria-expanded="false">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a href="index.html" class="site-logo"><img src="assets/img/logo.png" alt="logo" class="logo"></a>
                </div><!-- /.navbar-header -->

                <div class="main-menu" id="portfolio-perfect-collapse">

                    <ul class="nav navbar-nav navbar-right">

                        <li class="page-scroll"><a href="index.html#hero">Home</a></li>
                        <li class="page-scroll"><a href="index.html#about">About</a></li>
                        <li class="page-scroll"><a href="index.html#service">Service</a></li>
                        <li class="page-scroll"><a href="index.html#portfolio">Portfolio</a></li>
                        <li class="page-scroll"><a href="index.html#blog">Blog</a></li>
                        <li class="page-scroll"><a href="index.html#media">Media</a></li>
                        <li class="page-scroll"><a href="index.html#more-about-me">More about me</a></li>
                        <li class="page-scroll"><a href="index.html#contact">Contact</a></li>

                    </ul><!-- /.navbar-nav -->

                </div><!-- /.navbar-collapse -->

            </div>
        </nav><!-- /.primary-navigation -->
    </header><!-- /#header -->

    <div id="hero" class="hero">
    </div><!-- /.hero -->

    <main id="main" class="site-main">
        <!-- start section main content -->
        <section id="about" class="site-section section-about text-center blog-single">
            <div class="container" style="margin-bottom: 30px;">
                <img src="assets/img/project/secrets-perfect-ml-img.jpg" alt="signature" class="img-signature">
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-md-6 col-md-offset-3">
                        <h2>Unlock the Secrets to Choosing the Perfect Machine Learning Algorithm!</h2>
                        <img src="assets/img/lines.svg" class="img-lines" alt="lines">




                        <article>


                            <p>One of the key decisions you need to make when solving a data science problem is
                                which&nbsp;<a href="https://medium.com/p/313730eb5aa2" target="_blank"
                                    rel="noopener">machine learning</a>&nbsp;algorithm to use.</p>
                            <p>There are hundreds of machine learning algorithms to choose from, each with its own
                                advantages and disadvantages. Some algorithms may work better than others on specific
                                types of problems or on specific data sets.</p>
                            <p>The&nbsp;<a href="https://en.wikipedia.org/wiki/No_free_lunch_theorem" target="_blank"
                                    rel="noopener">&ldquo;No Free Lunch&rdquo; (NFL) theorem</a>&nbsp;states that there
                                is no one algorithm that works best for every problem, or in other words, all algorithms
                                have the same performance when their performance is averaged over all the possible
                                problems.</p>
                            <center><img src="https://www.kdnuggets.com/wp-content/uploads/ml-algorithm-choose_01.png"
                                    alt="Which ML Algorithm to Choose?" width="100%"
                                    data-lazy-src="/wp-content/uploads/ml-algorithm-choose_01.png"
                                    data-ll-status="loaded" /><br /> Different machine learning models</center>
                            <p>&nbsp;</p>
                            <p>In this article, we will discuss the main points you should consider when choosing a
                                model for your problem and how to compare different machine learning algorithms.</p>
                            <h4>Key Algorithm Aspects</h4>
                            <p>The following list contains 10 questions you may ask yourself when considering a specific
                                machine-learning algorithm:</p>

                            <li style="text-align: left;">Which type of problems can the algorithm solve? Can the
                                algorithm solve only
                                regression or classification problems, or can it solve both? Can it handle
                                multi-class/multi-label problems or only binary classification problems?</li>
                            <li style="text-align: left;">Does the algorithm have any assumptions about the data set?
                                For example, some
                                algorithms assume that the data is linearly separable (e.g., perceptron or linear
                                SVM), while others assume that the data is normally distributed (e.g., Gaussian
                                Mixture Models).</li>
                            <li style="text-align: left;">Are there any guarantees about the performance of the
                                algorithm? For example, if the
                                algorithm tries to solve an optimization problem (as in logistic regression or
                                neural networks), is it guaranteed to find the global optimum or only a local
                                optimum solution?</li>
                            <li style="text-align: left;">How much data is needed to train the model effectively? Some
                                algorithms, like deep
                                neural networks, are more data-savvy than others.</li>
                            <li style="text-align: left;">Does the algorithm tend to overfit? If so, does the algorithm
                                provide ways to deal
                                with overfitting?</li>
                            <li style="text-align: left;">What are the runtime and memory requirements of the algorithm,
                                both during training
                                and prediction time?</li>
                            <li style="text-align: left;">Which data preprocessing steps are required to prepare the
                                data for the algorithm?
                            </li>
                            <li style="text-align: left;">How many hyperparameters does the algorithm have? Algorithms
                                that have a lot of
                                hyperparameters take more time to train and tune.</li>
                            <li style="text-align: left;">Can the results of the algorithm be easily interpreted? In
                                many problem domains
                                (such as medical diagnosis), we would like to be able to explain the model&rsquo;s
                                predictions in human terms. Some models can be easily visualized (such as decision
                                trees), while others behave more like a black box (e.g., neural networks).</li>
                            <li style="text-align: left;">Does the algorithm support online (incremental) learning,
                                i.e., can we train it on
                                additional samples without rebuilding the model from scratch?</li>

                            <h4>Algorithm Comparison Example</h4>
                            <p>For example, let&rsquo;s take two of the most popular algorithms:&nbsp;<a
                                    href="https://medium.com/@roiyeho/decision-trees-part-1-da4e613d2369"
                                    target="_blank" rel="noopener">decision trees</a>&nbsp;and&nbsp;<a
                                    href="https://medium.com/@roiyeho/perceptrons-the-first-neural-network-model-8b3ee4513757"
                                    target="_blank" rel="noopener">neural networks</a>, and compare them
                                according to the above criteria.</p>
                            <h4>Decision Trees</h4>

                            <li style="text-align: left;">Decision trees can handle both classification and regression
                                problems. They
                                can also easily handle multi-class and multi-label problems.</li>
                            <li style="text-align: left;">Decision tree algorithms do not have any specific assumptions
                                about the data
                                set.</li>
                            <li style="text-align: left;">A decision tree is built using a greedy algorithm, which is
                                not guaranteed
                                to find the optimal tree (i.e., the tree that minimizes the number of tests
                                required to classify all the training samples correctly). However, a
                                decision tree can achieve 100% accuracy on the training set if we keep
                                extending its nodes until all the samples in the leaf nodes belong to the
                                same class. Such trees are usually not good predictors, as they overfit the
                                noise in the training set.</li>
                            <li style="text-align: left;">Decision trees can work well even on small or medium-sized
                                data sets.</li>
                            <li style="text-align: left;">Decision trees can easily overfit. However, we can reduce
                                overfitting by
                                using tree pruning. We can also use&nbsp;<a
                                    href="https://medium.com/@roiyeho/introduction-to-ensemble-methods-226a5a421687"
                                    target="_blank" rel="noopener">ensemble methods</a>&nbsp;such as random
                                forests that combine the output of multiple decision trees. These methods
                                suffer less from overfitting.</li>
                            <li style="text-align: left;">The time to build a decision tree
                                is&nbsp;<em>O</em>(<em>n</em>&sup2;<em>p</em>), where n is the number of
                                training samples, and&nbsp;<em>p</em>&nbsp;is the number of features. The
                                prediction time in decision trees depends on the height of the tree, which
                                is usually logarithmic in&nbsp;<em>n</em>, since most decision trees are
                                fairly balanced.</li>
                            <li style="text-align: left;">Decision trees do not require any data preprocessing. They can
                                seamlessly
                                handle different types of features, including numerical and categorical
                                features. They also do not require normalization of the data.</li>
                            <li style="text-align: left;">Decision trees have several key hyperparameters that need to
                                be tuned,
                                especially if you are using pruning, such as the maximum depth of the tree
                                and which impurity measure to use to decide how to split the nodes.</li>
                            <li style="text-align: left;">Decision trees are simple to understand and interpret, and we
                                can easily
                                visualize them (unless the tree is very large).</li>
                            <li style="text-align: left;">Decision trees cannot be easily modified to take into account
                                new training
                                samples since small changes in the data set can cause large changes in the
                                topology of the tree.</li>

                            <h4>Neural Networks</h4>

                            <li style="text-align: left;">Neural networks are one of the most general and flexible
                                machine learning
                                models that exist. They can solve almost any type of problem, including
                                classification, regression, time series analysis, automatic content
                                generation, etc.</li>
                            <li style="text-align: left;">Neural networks do not have assumptions about the data set,
                                but the data
                                needs to be normalized.</li>
                            <li style="text-align: left;">Neural networks are trained using gradient descent. Thus, they
                                can only find
                                a local optimum solution. However, there are various techniques that can be
                                used to avoid getting stuck in local minima, such as momentum and adaptive
                                learning rates.</li>
                            <li style="text-align: left;">Deep neural nets require a lot of data to train in the order
                                of millions of
                                sample points. In general, the larger the network is (the more layers and
                                neurons it has), more we need data to train it.</li>
                            <li style="text-align: left;">Networks that are too large might memorize all the training
                                samples and not
                                generalize well. For many problems, you can start from a small network
                                (e.g., with only one or two hidden layers) and gradually increase its size
                                until you start overfitting the training set. You can also add&nbsp;<a
                                    href="https://medium.com/@roiyeho/regularization-19b1879415a1" target="_blank"
                                    rel="noopener">regularization</a>&nbsp;in order to deal
                                with overfitting.</li>
                            <li style="text-align: left;">The training time of a neural network depends on many factors
                                (the size of
                                the network, the number of gradient descent iterations needed to train it,
                                etc.). However, prediction time is very fast since we only need to do one
                                forward pass over the network to get the label.</li>
                            <li style="text-align: left;">Neural networks require all the features to be numerical and
                                normalized.
                            </li>
                            <li style="text-align: left;">Neural networks have a lot of hyperparameters that need to be
                                tuned, such as
                                the number of layers, the number of neurons in each layer, which activation
                                function to use, the learning rate, etc.</li>
                            <li style="text-align: left;">The predictions of neural networks are hard to interpret as
                                they are based
                                on the computation of a large number of neurons, each of which has only a
                                small contribution to the final prediction.</li>
                            <li style="text-align: left;">Neural networks can easily adapt to include additional
                                training samples, as
                                they use an incremental learning algorithm (stochastic gradient descent).
                            </li>

                            <h4>Time Complexity</h4>
                            <p>The following table compares the training and prediction times of some
                                popular algorithms (<em>n</em>&nbsp;is the number of training samples
                                and&nbsp;<em>p</em>&nbsp;is the number of features).</p>
                            <center><img src="https://www.kdnuggets.com/wp-content/uploads/ml-algorithm-choose_02.png"
                                    alt="Which ML Algorithm to Choose?" width="100%"
                                    data-lazy-src="/wp-content/uploads/ml-algorithm-choose_02.png"
                                    data-ll-status="loaded" /></center>


                            <h4>Most Successful Algorithms in Kaggle Competitions</h4>
                            <p>According to a survey that was done in 2016, the most frequently used
                                algorithms by Kaggle competition winners were gradient boosting
                                algorithms (XGBoost) and neural networks (see&nbsp;<a
                                    href="https://www.kaggle.com/code/msjgriffiths/r-what-algorithms-are-most-successful-on-kaggle/report?scriptVersionId=0"
                                    target="_blank" rel="noopener">this article</a>).</p>
                            <p>Amongst the 29 Kaggle competition winners in 2015, 8 of them used
                                XGBoost, 9 used deep neural nets, and 11 used an ensemble of both.</p>
                            <p>XGBoost was mainly used in problems that dealt with structured data
                                (e.g., relational tables), whereas neural networks were more successful
                                in handling unstructured problems (e.g., problems that deal with image,
                                voice, or text).</p>
                            <p>It would be interesting to check if this is still the situation today or
                                whether the trends have changed (is anyone up for the challenge?)</p>
                            <p>Thanks for reading!</p>











                            <p class="mb-30">
                                <b>Author: Dr Roi Yehoshua</b>
                            </p>





                        </article>
                    </div>
                </div>
            </div>
        </section><!-- /.secton-about -->
        <!--  </div> -->
        <!-- start section main content -->

    </main><!-- /#main -->
    <footer id="colophon" class="site-footer">
        <div class="container">
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <a class="icon facebook-bg" href="#"><i class="ion-social-github"></i></a>
                    <a class="icon twitter-bg" href="#"><i class="ion-social-linkedin"></i></a>
                    <a class="icon gplus-bg" href="#"><i class="ion-social-whatsapp"></i></a>
                    <a class="icon gplus-bg" href="#"><i class="ion-email"></i></a>
                </div>
                <div class="col-sm-4 col-sm-offset-0 col-xs-6 col-xs-offset-3">
                    <p class="copyright">© Catalin Bondari 2024.</p>
                </div>
                <div class="col-sm-4 col-xs-3">
                    <div class="text-right page-scroll">
                        <a class="icon icon-up-bg" href="#hero"><i class="icon-up"></i></a>
                    </div>
                </div>
            </div>
        </div>

    </footer><!-- /#footer -->


    <!-- Bootstrap core JavaScript
================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
    <script src="assets/js/skrollr.min.js"></script>
    <script
        src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-progressbar/0.9.0/bootstrap-progressbar.min.js"></script>
    <script src="assets/js/jquery.countTo.min.js"></script>
    <script src="assets/js/script.js"></script>

</body>

</html>